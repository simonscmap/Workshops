{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/simonscmap/pycmap/blob/master/docs/figures/CMAP.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Mohammad Dehghani Ashkezari <mdehghan@uw.edu>* \n",
    "\n",
    "*Ginger Armbrust*\n",
    "\n",
    "*Raphael Hagen*\n",
    "\n",
    "*Michael Denholtz*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/simonscmap/pycmap/blob/master/docs/SCOPE2019.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a><a href=\"https://mybinder.org/v2/gh/simonscmap/pycmap/master?filepath=docs%2FSCOPE2019.ipynb\"><img align=\"right\" src=\"https://mybinder.org/badge_logo.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Binder\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"toc\"></a>\n",
    "\n",
    "## Table of Contents:\n",
    "* [Installation](#installation)\n",
    "* [**Data Retrieval (selected methods)**](#dataRetrieval)\n",
    "    * [API](#api) \n",
    "    * [Catalog](#catalog)\n",
    "    * [Search Catalog](#searchCatalog)\n",
    "    * [Cruise Trajectory](#cruiseTrajectory)\n",
    "    * [Subset by Space-Time](#spaceTime)\n",
    "    * [Colocalize Along Cruise Track](#matchCruise)\n",
    "    * [Query](#query)\n",
    "\n",
    "* [**Data Visulization**](https://cmap.readthedocs.io/en/latest/user_guide/API_ref/pycmap_api/pycmap_data_vizualization.html)\n",
    "    * [Histogram](https://cmap.readthedocs.io/en/latest/user_guide/API_ref/pycmap_api/pycmap_histogram.html#histogram)\n",
    "    * [Time Series](https://cmap.readthedocs.io/en/latest/user_guide/API_ref/pycmap_api/pycmap_time_series.html#timeseries)\n",
    "    * [Regional Map, Contour Plot, 3D Surface Plot](https://cmap.readthedocs.io/en/latest/user_guide/API_ref/pycmap_api/pycmap_rm_cp_3d.html#rmcp3d)\n",
    "    * [Section Map, Section Contour](https://cmap.readthedocs.io/en/latest/user_guide/API_ref/pycmap_api/pycmap_section_map_contour.html#sectionmapcontour)\n",
    "    * [Depth Profile](https://cmap.readthedocs.io/en/latest/user_guide/API_ref/pycmap_api/pycmap_depth_profile.html#depthprofile)\n",
    "    * [Cruise Track](https://cmap.readthedocs.io/en/latest/user_guide/API_ref/pycmap_api/pycmap_cruise_track.html#cruisetrackplot)\n",
    "    * [Correlation Matrix Along Cruise Track](https://cmap.readthedocs.io/en/latest/user_guide/API_ref/pycmap_api/pycmap_correlation_matrix_cruise_track.html#corrmatrixcruise)\n",
    "    \n",
    "* [**Case Studies**](#caseStudy)\n",
    "    * [Attach Environmental Parameters to the SeaFlow Observations](#caseStudy1)\n",
    "    * [Inter-Annual Variability of Eddy Induced Temperature Anomaly](#caseStudy2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"dataRetrieval\"></a>\n",
    "<br/><br/><br/><br/><br/><br/><br/><br/>\n",
    "<center>\n",
    "<h1> API: Data Retrieval </h1>\n",
    "</center>\n",
    "<br/><br/><br/><br/><br/><br/><br/><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable intellisense\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"installation\"></a> \n",
    "<a href=\"#toc\" style=\"float: right;\">Table of Contents</a>\n",
    "## Installation\n",
    "pycmap can be installed using *pip*: \n",
    "<br />`pip install pycmap`\n",
    "\n",
    "In order to use pycmap, you will need to obtain an API key from SimonsCMAP website:\n",
    "<a href=\"https://simonscmap.com\">https://simonscmap.com</a>.\n",
    "\n",
    "### Note:\n",
    "You may install pycmap on cloud-based jupyter notebooks (such as [Colab](https://colab.research.google.com/)) by running the following command in a code-block: \n",
    "<br />`!pip install pycmap`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pycmap -q    #uncomment to install pycmap on Colab\n",
    "import pycmap\n",
    "pycmap.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"api\"></a>\n",
    "<a href=\"#toc\" style=\"float: right;\">Table of Contents</a>\n",
    "## [*API( )*](https://cmap.readthedocs.io/en/latest/user_guide/API_ref/pycmap_api/pycmap_api.html#pycmapapi)\n",
    "To retrieve data, we need to create an instance of the system's API and pass the API key. It is not necessary to pass the API key every time you run pycmap, because the key will be stored locally. The API class has other optional parameters to adjust its behavior. All parameters can be updated persistently at any point in the code.\n",
    "\n",
    "Register at https://simonscmap.com and get and API key, if you haven't already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = pycmap.API()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"catalog\"></a>\n",
    "<a href=\"#toc\" style=\"float: right;\">Table of Contents</a>\n",
    "## [*get_catalog()*](https://cmap.readthedocs.io/en/latest/user_guide/API_ref/pycmap_api/pycmap_catalog.html#getcatalog)\n",
    "\n",
    "Returns a dataframe containing the details of all variables at Simons CMAP database. \n",
    "<br />This method requires no input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.get_catalog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"searchCatalog\"></a>\n",
    "<a href=\"#toc\" style=\"float: right;\">Table of Contents</a>\n",
    "## [*search_catalog(keywords)*](https://cmap.readthedocs.io/en/latest/user_guide/API_ref/pycmap_api/pycmap_search_catalog.html#searchcatalog)\n",
    "\n",
    "\n",
    "Returns a dataframe containing a subset of Simons CMAP catalog of variables. \n",
    "\n",
    "All variables at Simons CMAP catalog are annotated with a collection of semantically related keywords. This method takes the passed keywords and returns all of the variables annotated with similar keywords. The passed keywords should be separated by blank space. The search result is not sensitive to the order of keywords and is not case sensitive. The passed keywords can provide any 'hint' associated with the target variables. Below are a few examples: \n",
    "\n",
    "* the exact variable name (e.g. NO3), or its linguistic term (Nitrate) \n",
    "* methodology (model, satellite ...), instrument (CTD, seaflow), or disciplines (physics, biology ...) \n",
    "* the cruise official name (e.g. KOK1606), or unofficial cruise name (Falkor) \n",
    "* the name of data producer (e.g Penny Chisholm) or institution name (MIT) \n",
    "\n",
    "<br />If you searched for a variable with semantically-related-keywords and did not get the correct results, please let us know. We can update the keywords at any point.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:\n",
    "Returns a list of Nitrite measurements during the Falkor cruise, if exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.search_catalog('nitrite falkor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"cruiseTrajectory\"></a>\n",
    "<a href=\"#toc\" style=\"float: right;\">Table of Contents</a>\n",
    "## [*cruise_trajectory(cruiseName)*](https://cmap.readthedocs.io/en/latest/user_guide/API_ref/pycmap_api/pycmap_cruise_trajectory.html#cruise-traj)\n",
    "\n",
    "Returns a dataframe containing the trajectory of the specified cruise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:\n",
    "Returns the meso_scope cruise trajectory.\n",
    "The example below passes 'scope' as cruise name. All cruises that have the term 'scope' in their name are returned and asks for more specific name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.cruise_trajectory('scope')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"cruiseVariables\"></a>\n",
    "<a href=\"#toc\" style=\"float: right;\">Table of Contents</a>\n",
    "## [*cruise_variables(cruiseName)*](https://cmap.readthedocs.io/en/latest/user_guide/API_ref/pycmap_api/pycmap_cruise_variables.html#cruisevars)\n",
    "\n",
    "Returns a dataframe containing all registered variables (at Simons CMAP) during the specified cruise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:\n",
    "Returns a list of measured variables during the *Diel* cruise (KM1513)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.cruise_variables('diel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"spaceTime\"></a>\n",
    "<a href=\"#toc\" style=\"float: right;\">Table of Contents</a>\n",
    "## [*space_time(table, variable, dt1, dt2, lat1, lat2, lon1, lon2, depth1, depth2)*](https://cmap.readthedocs.io/en/latest/user_guide/API_ref/pycmap_api/pycmap_subset_ST.html#subset-st)\n",
    "\n",
    "Returns a subset of data according to the specified space-time constraints (dt1, dt2, lat1, lat2, lon1, lon2, depth1, depth2).\n",
    "<br />The results are ordered by time, lat, lon, and depth (if exists), respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Parameters:** \n",
    ">> **table: string**\n",
    ">>  <br />Table name (each dataset is stored in a table). A full list of table names can be found in [catalog](https://cmap.readthedocs.io/en/latest/user_guide/API_ref/pycmap_api/pycmap_catalog.html#getcatalog).\n",
    ">> <br />\n",
    ">> <br />**variable: string**\n",
    ">>  <br />Variable short name which directly corresponds to a field name in the table. A subset of this variable is returned by this method according to the spatio-temporal cut parameters (below). Pass **'\\*'** wild card to retrieve all fields in a table. A full list of variable short names can be found in [catalog](https://cmap.readthedocs.io/en/latest/user_guide/API_ref/pycmap_api/pycmap_catalog.html#getcatalog).\n",
    ">> <br />\n",
    ">> <br />**dt1: string**\n",
    ">>  <br />Start date or datetime. This parameter sets the lower bound of the temporal cut. <br />Example values: '2016-05-25' or '2017-12-10 17:25:00'\n",
    ">> <br />\n",
    ">> <br />**dt2: string**\n",
    ">>  <br />End date or datetime. This parameter sets the upper bound of the temporal cut. \n",
    ">> <br />\n",
    ">> <br />**lat1: float**\n",
    ">>  <br />Start latitude [degree N]. This parameter sets the lower bound of the meridional cut. Note latitude ranges from -90&deg; to 90&deg;.\n",
    ">> <br />\n",
    ">> <br />**lat2: float**\n",
    ">>  <br />End latitude [degree N]. This parameter sets the upper bound of the meridional cut. Note latitude ranges from -90&deg; to 90&deg;.\n",
    ">> <br />\n",
    ">> <br />**lon1: float**\n",
    ">>  <br />Start longitude [degree E]. This parameter sets the lower bound of the zonal cut. Note longitue ranges from -180&deg; to 180&deg;.\n",
    ">> <br />\n",
    ">> <br />**lon2: float**\n",
    ">>  <br />End longitude [degree E]. This parameter sets the upper bound of the zonal cut. Note longitue ranges from -180&deg; to 180&deg;.\n",
    ">> <br />\n",
    ">> <br />**depth1: float**\n",
    ">>  <br />Start depth [m]. This parameter sets the lower bound of the vertical cut. Note depth is a positive number (it is 0 at surface and grows towards ocean floor).\n",
    ">> <br />\n",
    ">> <br />**depth2: float**\n",
    ">>  <br />End depth [m]. This parameter sets the upper bound of the vertical cut. Note depth is a positive number (it is 0 at surface and grows towards ocean floor).\n",
    "\n",
    "\n",
    ">**Returns:** \n",
    ">>  Pandas dataframe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:\n",
    "This example retrieves a subset of in-situ salinity measurements by [Argo floats](https://cmap.readthedocs.io/en/latest/catalog/datasets/Argo.html#argo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.space_time(\n",
    "              table='tblArgoMerge_REP', \n",
    "              variable='argo_merge_salinity_adj', \n",
    "              dt1='2015-05-01', \n",
    "              dt2='2015-05-30', \n",
    "              lat1=28, \n",
    "              lat2=38, \n",
    "              lon1=-71, \n",
    "              lon2=-50, \n",
    "              depth1=0, \n",
    "              depth2=100\n",
    "              ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"matchCruise\"></a>\n",
    "<a href=\"#toc\" style=\"float: right;\">Table of Contents</a>\n",
    "\n",
    "## [*along_track(cruise, targetTables, targetVars, depth1, depth2, temporalTolerance, latTolerance, lonTolerance, depthTolerance)*](https://cmap.readthedocs.io/en/latest/user_guide/API_ref/pycmap_api/pycmap_match_cruise_track_datasets.html#matchcruise)\n",
    "\n",
    "This method colocalizes a cruise trajectory with the specified target variables. The matching results rely on the tolerance parameters because these parameters set the matching boundaries between the cruise trajectory and target datasets. Please note that the number of matching entries for each target variable might vary depending on the temporal and spatial resolutions of the target variable. In principle, if the cruise trajectory is fully covered by the target variable's spatio-temporal range, there should always be matching results if the tolerance parameters are larger than half of their corresponding spatial/temporal resolutions. Please explore the [catalog](https://cmap.readthedocs.io/en/latest/user_guide/API_ref/pycmap_api/pycmap_catalog.html#getcatalog) to find appropriate target variables to colocalize with the desired cruise. \n",
    "\n",
    "<br />This method returns a dataframe containing the cruise trajectory joined with the target variable(s).\n",
    "\n",
    "## <br/><br/>(see slides &rarr;)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Parameters:** \n",
    ">> **cruise: string**\n",
    ">>  <br />The official cruise name. If applicable, you may also use cruise \"nickname\" ('Diel', 'Gradients_1' ...). <br />A full list of cruise names can be retrieved using [cruise](https://cmap.readthedocs.io/en/latest/user_guide/API_ref/pycmap_api/pycmap_catalog.html#getcatalog) method.\n",
    ">> <br />\n",
    ">> <br />**targetTables: list of string**\n",
    ">>  <br />Table names of the target datasets to be matched with the cruise trajectory. Notice cruise trajectory can be matched with multiple target datasets. A full list of table names can be found in [catalog](https://cmap.readthedocs.io/en/latest/user_guide/API_ref/pycmap_api/pycmap_catalog.html#getcatalog).\n",
    ">> <br />\n",
    ">> <br />**targetVars: list of string**\n",
    ">>  <br />Variable short names to be matched with the cruise trajectory. A full list of variable short names can be found in [catalog](https://cmap.readthedocs.io/en/latest/user_guide/API_ref/pycmap_api/pycmap_catalog.html#getcatalog).\n",
    ">> <br />\n",
    ">> <br />**depth1: float**\n",
    ">>  <br />Start depth [m]. This parameter sets the lower bound of the depth cut on the traget datasets. 'depth1' and 'depth2' allow matching a cruise trajectory (which is at the surface, hopefully!) with traget varaiables at lower depth. Note depth is a positive number (depth is 0 at surface and grows towards ocean floor).\n",
    ">> <br />\n",
    ">> <br />**depth2: float**\n",
    ">>  <br />End depth [m]. This parameter sets the upper bound of the depth cut on the traget datasets. Note depth is a positive number (depth is 0 at surface and grows towards ocean floor).\n",
    ">> <br />\n",
    ">> <br />**temporalTolerance: list of int**\n",
    ">> <br />Temporal tolerance values between the cruise trajectory and target datasets. The size and order of values in this list should match those of targetTables. If only a single integer value is given, that would be applied to all target datasets. This parameter is in day units except when the target variable represents monthly climatology data in which case it is in month units. Notice fractional values are not supported in the current version.\n",
    ">> <br />\n",
    ">> <br />**latTolerance: list of float or int**\n",
    ">> <br />Spatial tolerance values in meridional direction [deg] between the cruise trajectory and target datasets. The size and order of values in this list should match those of targetTables. If only a single float value is given, that would be applied to all target datasets. A \"safe\" value for this parameter can be slightly larger than the half of the traget variable's spatial resolution.\n",
    ">> <br />\n",
    ">> <br />**lonTolerance: list of float or int**\n",
    ">> <br />Spatial tolerance values in zonal direction [deg] between the cruise trajectory and target datasets. The size and order of values in this list should match those of targetTables. If only a single float value is given, that would be applied to all target datasets. A \"safe\" value for this parameter can be slightly larger than the half of the traget variable's spatial resolution.\n",
    ">> <br />\n",
    ">> <br />**depthTolerance: list of float or int**\n",
    ">> <br />Spatial tolerance values in vertical direction [m] between the cruise trajectory and target datasets. The size and order of values in this list should match those of targetTables. If only a single float value is given, that would be applied to all target datasets. \n",
    "\n",
    ">**Returns:** \n",
    ">>  Pandas dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:\n",
    "Colocalizes the Gradients_1 cruise with prochloro_abundance and prokaryote_c01_darwin_clim variables from the Seaflow and Darwin (climatology) Data sets, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pycmap\n",
    "\n",
    "api = pycmap.API()\n",
    "df = api.along_track(\n",
    "                    cruise='gradients_3', \n",
    "                    targetTables=['tblSeaFlow', 'tblDarwin_Nutrient_Climatology'],\n",
    "                    targetVars=['prochloro_abundance', 'PO4_darwin_clim'],\n",
    "                    depth1=0, \n",
    "                    depth2=5, \n",
    "                    temporalTolerance=[0, 0],\n",
    "                    latTolerance=[0.01, 0.25],\n",
    "                    lonTolerance=[0.01, 0.25],\n",
    "                    depthTolerance=[5, 5]\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################# Simple Plot #################\n",
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "c1, c2 = 'firebrick', 'slateblue'\n",
    "t1, t2 = 'tblSeaFlow', 'tblDarwin_Nutrient_Climatology'\n",
    "v1, v2 = 'prochloro_abundance', 'PO4_darwin_clim'\n",
    "ax1.plot(df['lat'], df[v1], 'o', color=c1, markeredgewidth=0, label='SeaFlow', alpha=0.2)\n",
    "ax1.tick_params(axis='y', labelcolor='r')\n",
    "ax1.set_ylabel(v1 + api.get_unit(t1, v1), color='r')\n",
    "ax2.plot(df['lat'], df[v2], 'o', color=c2, markeredgewidth=0, label='Darwin', alpha=0.2)\n",
    "ax2.tick_params(axis='y', labelcolor='b')\n",
    "ax2.set_ylabel(v2 + api.get_unit(t2, v2), color='b')\n",
    "ax1.set_xlabel('Latitude')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"query\"></a>\n",
    "<a href=\"#toc\" style=\"float: right;\">Table of Contents</a>\n",
    "## [*query(query)*](https://cmap.readthedocs.io/en/latest/user_guide/API_ref/pycmap_api/pycmap_query.html#query)\n",
    "<br />Simons CMAP datasets are hosted in a SQL database and pycmap package provides the user with a number of pre-developed methods to extract and retrieve subsets of the data. The rest of this documentation is dedicated to explore and explain these methods. In addition to the pre-developed methods, we intend to leave the database open to custom scan queries for interested users. This method takes a custom SQL query statement and returns the results in form of a Pandas dataframe. The full list of table names and variable names (fields) can be obtained using the [get_catalog()](Catalog.ipynb) method. In fact, one may use this very method to retrieve the table and field names: `query('EXEC uspCatalog')`. A Dataset is stored in a table and each table field represents a variable. All data tables have the following fields:\n",
    "\n",
    "* [time] [date or datetime] NOT NULL,\n",
    "* [lat] [float] NOT NULL,\n",
    "* [lon] [float] NOT NULL,\n",
    "* [depth] [float] NOT NULL,\n",
    "\n",
    "### Note:\n",
    "Tables which represent a climatological dataset, such as 'tblDarwin_Nutrient_Climatology', will not have a 'time' field. Also, if a table represents a surface dataset, such as satellite products, there would be no 'depth' field. 'depth' is a positive number in meters unit; it is zero at the surface growing towards the ocean's floor. 'lat' and 'lon' are in degrees units, ranging from -90&deg; to 90&deg; and -180&deg; to 180&deg;, respectively.\n",
    "\n",
    "<br />Please keep in mind that some of the datasets are massive in size (10s of TB), avoid queries without WHERE clause (`SELECT * FROM TABLENAME`). Always try to add some constraints on time, lat, lon, and depth fields (see the basic examples below). \n",
    "\n",
    "<br/>Moreover, the database hosts a wide range of predefined stored procedures and functions to streamline nearly all CMAP data services. For instance retrieving the catalog information is achieved using a single call of this procedure: *uspCatalog*. These predefined procedures can be called using the pycmap package (see example below). Alternatively, one may use any SQL client to execute these procedures to retrieve and visualize data (examples: [Azure Data Studio](https://docs.microsoft.com/en-us/sql/azure-data-studio/download?view=sql-server-ver15), or [Plotly Falcon](https://plot.ly/free-sql-client-download/)). Using the predefined procedures all CMAP data services are centralized at the database layer which dramatically facilitates the process of developing apps with different programming languages (pycmap, web app, cmap4r, ...). Please note that you can improve the current procedures or add new procedures by contributing at the [CMAP database repository](https://github.com/simonscmap/DB). \n",
    "Below is a selected list of stored procedures and functions, their arguments will be described in more details subsequently:\n",
    "\n",
    "\n",
    "\n",
    "* uspCatalog\n",
    "* uspSpaceTime\n",
    "* uspTimeSeries\n",
    "* uspDepthProfile\n",
    "* uspSectionMap\n",
    "* uspCruises\n",
    "* uspCruiseByName\n",
    "* uspCruiseBounds\n",
    "* uspWeekly\n",
    "* uspMonthly\n",
    "* uspQuarterly\n",
    "* uspAnnual\n",
    "* uspMatch\n",
    "* udfDatasetReferences\n",
    "* udfMetaData_NoRef\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br />Happy SQL Injection!\n",
    "<br />\n",
    "<br />\n",
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:\n",
    "A sample stored procedure returning the list of all cruises hosted by Simons CMAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.query('EXEC uspCruises')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:\n",
    "A sample query returning the timeseries of sea surface temperature (sst)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.query(\n",
    "         '''\n",
    "         SELECT [time], AVG(lat) AS lat, AVG(lon) AS lon, AVG(sst) AS sst FROM tblsst_AVHRR_OI_NRT\n",
    "         WHERE\n",
    "         [time] BETWEEN '2016-06-01' AND '2016-10-01' AND\n",
    "         lat BETWEEN 23 AND 24 AND\n",
    "         lon BETWEEN -160 AND -158\n",
    "         GROUP BY [time]\n",
    "         ORDER BY [time]\n",
    "         '''\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"caseStudy\"></a>\n",
    "<br/><br/><br/><br/><br/><br/><br/><br/>\n",
    "<center>\n",
    "<h1> Study Cases </h1>\n",
    "</center>\n",
    "<br/><br/><br/><br/><br/><br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"caseStudy1\"></a>\n",
    "<a href=\"#toc\" style=\"float: right;\">Table of Contents</a>\n",
    "## (see slides &rarr;)<br/><br/>\n",
    "## Case Study 1: <br/><br/> Attach Environmental Parameters to the SeaFlow Observations \n",
    "\n",
    "In this study, we take all seaflow cruises (approximately 35 cruises) and colocalize them with 50+ environmental variables. The idea is to identify the highly-correlated environmental variables (correlated with seaflow abundances). These variables then serve as predictors of machine learning algorithms that capture the seaflow variations. The trained machine learning models then are used to generate spatial maps of pico-phytoplanktons (Prochlorococcus, Synechococcus, and pico-Eukaryotes).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Mohammad Dehghani Ashkezari <mdehghan@uw.edu>\n",
    "\n",
    "Date: 2019-08-13\n",
    "\n",
    "Function: Colocalizes tens of variables along-track of cruises with underway Seaflow measurements.\n",
    "\"\"\"\n",
    "\n",
    "%%time\n",
    "import os\n",
    "import pycmap\n",
    "from collections import namedtuple\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def all_cruises(api):\n",
    "    \"\"\"\n",
    "    Returns a list of seaflow cruises, excluding the AMT cruises.\n",
    "    \"\"\"\n",
    "    cruises = api.cruises().Name\n",
    "    return list(cruises[~cruises.str.contains(\"AMT\")])\n",
    "\n",
    "\n",
    "def match_params():\n",
    "    \"\"\"\n",
    "    Creates a collection of variables (and their tolerances) to be colocalized along the cruise trajectory.\n",
    "    \"\"\"\n",
    "    Param = namedtuple('Param', ['table', 'variable', 'temporalTolerance', 'latTolerance', 'lonTolerance', 'depthTolerance'])\n",
    "    params = []\n",
    "    params.append(Param('tblSeaFlow', 'prochloro_abundance', 0, 0.1, 0.1, 5))\n",
    "    params.append(Param('tblSeaFlow', 'prochloro_diameter', 0, 0.1, 0.1, 5))\n",
    "    params.append(Param('tblSeaFlow', 'prochloro_carbon_content', 0, 0.1, 0.1, 5))\n",
    "    params.append(Param('tblSeaFlow', 'prochloro_biomass', 0, 0.1, 0.1, 5))\n",
    "    params.append(Param('tblSeaFlow', 'synecho_abundance', 0, 0.1, 0.1, 5))\n",
    "    params.append(Param('tblSeaFlow', 'synecho_diameter', 0, 0.1, 0.1, 5))\n",
    "    params.append(Param('tblSeaFlow', 'synecho_carbon_content', 0, 0.1, 0.1, 5))\n",
    "    params.append(Param('tblSeaFlow', 'synecho_biomass', 0, 0.1, 0.1, 5))\n",
    "    params.append(Param('tblSeaFlow', 'picoeuk_abundance', 0, 0.1, 0.1, 5))\n",
    "    params.append(Param('tblSeaFlow', 'picoeuk_diameter', 0, 0.1, 0.1, 5))\n",
    "    params.append(Param('tblSeaFlow', 'picoeuk_carbon_content', 0, 0.1, 0.1, 5))\n",
    "    params.append(Param('tblSeaFlow', 'picoeuk_biomass', 0, 0.1, 0.1, 5))\n",
    "    params.append(Param('tblSeaFlow', 'total_biomass', 0, 0.1, 0.1, 5))\n",
    "\n",
    "    ######## Ship Data (not calibrated)\n",
    "    params.append(Param('tblCruise_Salinity', 'salinity', 0, 0.1, 0.1, 5))\n",
    "    params.append(Param('tblCruise_Temperature', 'temperature', 0, 0.1, 0.1, 5))\n",
    "\n",
    "    ######## satellite\n",
    "    params.append(Param('tblSST_AVHRR_OI_NRT', 'sst', 1, 0.25, 0.25, 5))\n",
    "    params.append(Param('tblSSS_NRT', 'sss', 1, 0.25, 0.25, 5))\n",
    "    params.append(Param('tblCHL_REP', 'chl', 4, 0.25, 0.25, 5))\n",
    "    params.append(Param('tblModis_AOD_REP', 'AOD', 15, 1, 1, 5))\n",
    "    params.append(Param('tblAltimetry_REP', 'sla', 1, 0.25, 0.25, 5))\n",
    "    params.append(Param('tblAltimetry_REP', 'adt', 1, 0.25, 0.25, 5))\n",
    "    params.append(Param('tblAltimetry_REP', 'ugos', 1, 0.25, 0.25, 5))\n",
    "    params.append(Param('tblAltimetry_REP', 'vgos', 1, 0.25, 0.25, 5))\n",
    "\n",
    "    ######## model\n",
    "    params.append(Param('tblPisces_NRT', 'Fe', 4, 0.5, 0.5, 5))\n",
    "    params.append(Param('tblPisces_NRT', 'NO3', 4, 0.5, 0.5, 5))\n",
    "    params.append(Param('tblPisces_NRT', 'O2', 4, 0.5, 0.5, 5))\n",
    "    params.append(Param('tblPisces_NRT', 'PO4', 4, 0.5, 0.5, 5))\n",
    "    params.append(Param('tblPisces_NRT', 'Si', 4, 0.5, 0.5, 5))\n",
    "    params.append(Param('tblPisces_NRT', 'PP', 4, 0.5, 0.5, 5))\n",
    "    params.append(Param('tblPisces_NRT', 'CHL', 4, 0.5, 0.5, 5))\n",
    "    params.append(Param('tblDarwin_Nutrient_Climatology', 'NH4_darwin_clim', 0, 0.5, 0.5, 5))\n",
    "    params.append(Param('tblDarwin_Nutrient_Climatology', 'NO2_darwin_clim', 0, 0.5, 0.5, 5))\n",
    "    params.append(Param('tblDarwin_Nutrient_Climatology', 'SiO2_darwin_clim', 0, 0.5, 0.5, 5))\n",
    "    params.append(Param('tblDarwin_Nutrient_Climatology', 'DOC_darwin_clim', 0, 0.5, 0.5, 5))\n",
    "    params.append(Param('tblDarwin_Nutrient_Climatology', 'DON_darwin_clim', 0, 0.5, 0.5, 5))\n",
    "    params.append(Param('tblDarwin_Nutrient_Climatology', 'DOP_darwin_clim', 0, 0.5, 0.5, 5))\n",
    "    params.append(Param('tblDarwin_Nutrient_Climatology', 'DOFe_darwin_clim', 0, 0.5, 0.5, 5))\n",
    "    params.append(Param('tblDarwin_Nutrient_Climatology', 'PIC_darwin_clim', 0, 0.5, 0.5, 5))\n",
    "    params.append(Param('tblDarwin_Nutrient_Climatology', 'ALK_darwin_clim', 0, 0.5, 0.5, 5))\n",
    "    params.append(Param('tblDarwin_Nutrient_Climatology', 'FeT_darwin_clim', 0, 0.5, 0.5, 5))\n",
    "    params.append(Param('tblDarwin_Plankton_Climatology', 'prokaryote_c01_darwin_clim', 0, 0.5, 0.5, 5))\n",
    "    params.append(Param('tblDarwin_Plankton_Climatology', 'prokaryote_c02_darwin_clim', 0, 0.5, 0.5, 5))\n",
    "    params.append(Param('tblDarwin_Plankton_Climatology', 'picoeukaryote_c03_darwin_clim', 0, 0.5, 0.5, 5))\n",
    "    params.append(Param('tblDarwin_Plankton_Climatology', 'picoeukaryote_c04_darwin_clim', 0, 0.5, 0.5, 5))\n",
    "\n",
    "    ####### World Ocean Atlas (WOA)\n",
    "    params.append(Param('tblWOA_Climatology', 'density_WOA_clim', 0, .75, .75, 5))\n",
    "    params.append(Param('tblWOA_Climatology', 'nitrate_WOA_clim', 0, 0.75, 0.75, 5))\n",
    "    params.append(Param('tblWOA_Climatology', 'phosphate_WOA_clim', 0, 0.75, 0.75, 5))\n",
    "    params.append(Param('tblWOA_Climatology', 'silicate_WOA_clim', 0, 0.75, 0.75, 5))\n",
    "    params.append(Param('tblWOA_Climatology', 'oxygen_WOA_clim', 0, 0.75, 0.75, 5))\n",
    "    params.append(Param('tblWOA_Climatology', 'salinity_WOA_clim', 0, 0.75, 0.75, 5))\n",
    "\n",
    "    tables, variables, temporalTolerance, latTolerance, lonTolerance, depthTolerance = [], [], [], [], [], []\n",
    "    for i in range(len(params)):\n",
    "        tables.append(params[i].table)\n",
    "        variables.append(params[i].variable)\n",
    "        temporalTolerance.append(params[i].temporalTolerance)\n",
    "        latTolerance.append(params[i].latTolerance)\n",
    "        lonTolerance.append(params[i].lonTolerance)\n",
    "        depthTolerance.append(params[i].depthTolerance)\n",
    "    return tables, variables, temporalTolerance, latTolerance, lonTolerance, depthTolerance\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    api = pycmap.API()\n",
    "    cruises = all_cruises(api)\n",
    "    cruises = ['KOK1606']   # limiting to only one cruise (for presentation)\n",
    "    exportDir = './export/'\n",
    "    if not os.path.exists(exportDir): os.makedirs(exportDir) \n",
    "    tables, variables, temporalTolerance, latTolerance, lonTolerance, depthTolerance = match_params()\n",
    "    df = pd.DataFrame({})\n",
    "    for cruise in cruises:\n",
    "        print('\\n********************************')\n",
    "        print('Preparing %s cruise...' % cruise)\n",
    "        print('********************************\\n')\n",
    "        data = api.along_track(\n",
    "                              cruise=cruise,     \n",
    "                              targetTables=tables,\n",
    "                              targetVars=variables,\n",
    "                              temporalTolerance=temporalTolerance, \n",
    "                              latTolerance=latTolerance, \n",
    "                              lonTolerance=lonTolerance, \n",
    "                              depthTolerance=depthTolerance,\n",
    "                              depth1=0,\n",
    "                              depth2=5\n",
    "                              )\n",
    "        if len(df) < 1:\n",
    "            df = data\n",
    "        else:\n",
    "            df = pd.concat([df, data], ignore_index=True)\n",
    "        data.to_csv('%s%s.csv' % (exportDir, cruise), index=False)\n",
    "    df.to_csv('%ssfMatch.csv' % exportDir, index=False)      \n",
    "    return df    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "##############################\n",
    "#                            #\n",
    "#           main             #\n",
    "#                            #\n",
    "##############################\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    df = main()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"caseStudy2\"></a>\n",
    "<a href=\"#toc\" style=\"float: right;\">Table of Contents</a>\n",
    "## (see slides &rarr;)<br/><br/>\n",
    "## Case Study 2: <br/><br/>Inter-Annual Variability of Eddy Induced Temperature Anomaly \n",
    "In this example, we iteratively retrieve daily eddy locations and colocalize them with satellite and model variables (SST, CHL, SLA, and NO3). To infer the eddy induced effects we also compute an estimate of the local background. Subtracting the background field from that of eddy domain results in the eddy induced effects. For demonstration purposes, the script below is limited to a small region within a one-day period (see the root of the script)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Mohammad Dehghani Ashkezari <mdehghan@uw.edu>\n",
    "\n",
    "Date: 2019-11-01\n",
    "\n",
    "Function: Colocalize (match) eddy data set with a number of satellite & model variables (e.g. SST, CHL, NO3, etc ...).\n",
    "\"\"\"\n",
    "\n",
    "%%time\n",
    "import os\n",
    "import pycmap\n",
    "from collections import namedtuple\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta, date\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sparse_dates(y1, y2, m1, m2, d1, d2):\n",
    "    dts = []\n",
    "    for y in range(y1, y2+1):\n",
    "        for m in range(m1, m2+1):\n",
    "            for d in range(d1, d2+1):\n",
    "                dts.append(datetime(y, m, d))\n",
    "    return dts            \n",
    "\n",
    "\n",
    "def eddy_time_range(api):\n",
    "    \"\"\"\n",
    "    Returns the start-date and end-date of the eddy dataset.\n",
    "    \"\"\"\n",
    "    query = \"SELECT min([time]) AS min_time, max([time]) max_time FROM tblMesoscale_Eddy\"\n",
    "    df = api.query(query)\n",
    "    dt1 = datetime.strptime(df.loc[0, 'min_time'], '%Y-%m-%dT%H:%M:%S.000Z')\n",
    "    dt2 = datetime.strptime(df.loc[0, 'max_time'], '%Y-%m-%dT%H:%M:%S.000Z')\n",
    "    return [dt1 + timedelta(days=x) for x in range((dt2-dt1).days + 1)]\n",
    "\n",
    "\n",
    "def daily_eddies(api, day, lat1, lat2, lon1, lon2):\n",
    "    \"\"\"\n",
    "    Returns eddies at a given date (day) delimited by the spatial parameters (lat1, lat2, lon1, lon2).\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "            SELECT * FROM tblMesoscale_Eddy \n",
    "            WHERE \n",
    "            [time]='%s' \n",
    "            AND\n",
    "            lat BETWEEN %f AND %f AND\n",
    "            lon BETWEEN %f AND %f\n",
    "            \"\"\" % (day, lat1, lat2, lon1, lon2)\n",
    "    return api.query(query)\n",
    "\n",
    "\n",
    "def match_covariate(api, table, variable, dt1, dt2, lat, del_lat, lon, del_lon, depth, del_depth):\n",
    "    \"\"\"\n",
    "    Returns the mean and standard-deviation of variable within the eddy domain and with the background field.\n",
    "    \"\"\"\n",
    "\n",
    "    def has_depth(table):\n",
    "        return table in ['tblPisces_NRT', 'tblDarwin_Nutrient', 'tblDarwin_Ecosystem', 'tblDarwin_Phytoplankton']\n",
    "    query = \"SELECT AVG(%s) AS %s, STDEV(%s) AS %s FROM %s \" % (variable, variable, variable, variable+'_std', table)\n",
    "    query += \"WHERE [time] BETWEEN '%s' AND '%s' AND \" % (dt1, dt2)\n",
    "    query += \"[lat] BETWEEN %f AND %f AND \" % (lat-del_lat, lat+del_lat)\n",
    "    query += \"[lon] BETWEEN %f AND %f \" % (lon-del_lon, lon+del_lon)\n",
    "    if has_depth(table):   \n",
    "        query += \" AND [depth] BETWEEN %f AND %f \" % (depth-del_depth, depth+del_depth)\n",
    "    try:\n",
    "        signal = api.query(query)\n",
    "    except:\n",
    "        return None, None, None, None    \n",
    "\n",
    "    outer, inner = 4, 2\n",
    "    query = \"SELECT AVG(%s) AS %s, STDEV(%s) AS %s FROM %s \" % (variable, variable+'_bkg', variable, variable+'_bkg_std', table)\n",
    "    query += \"WHERE [time] BETWEEN '%s' AND '%s' AND \" % (dt1, dt2)\n",
    "    query += \"[lat] BETWEEN %f AND %f AND \" % (lat-outer*del_lat, lat+outer*del_lat)\n",
    "    query += \"[lat] NOT BETWEEN %f AND %f AND \" % (lat-inner*del_lat, lat+inner*del_lat)\n",
    "    query += \"[lon] BETWEEN %f AND %f AND \" % (lon-outer*del_lon, lon+outer*del_lon)\n",
    "    query += \"[lon] NOT BETWEEN %f AND %f \" % (lon-inner*del_lon, lon+inner*del_lon)\n",
    "    if has_depth(table):    \n",
    "        query += \"AND [depth] BETWEEN %f AND %f \" % (depth-del_depth, depth+del_depth)\n",
    "    try:     \n",
    "        background = api.query(query)\n",
    "    except:\n",
    "        return None, None, None, None    \n",
    "    sig, sig_bkg = None, None\n",
    "    try:\n",
    "        if len(signal)>0: sig, sig_bkg = signal.loc[0, variable], signal.loc[0, variable+'_std']\n",
    "    except:\n",
    "        sig, sig_bkg = None, None    \n",
    "    bkg, bkg_std = None, None\n",
    "    try:\n",
    "        if len(background)>0: bkg, bkg_std = background.loc[0, variable+'_bkg'], background.loc[0, variable+'_bkg_std']\n",
    "    except:\n",
    "        bkg, bkg_std = None, None    \n",
    "    return sig, sig_bkg, bkg, bkg_std \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def match_params():\n",
    "    \"\"\"\n",
    "    Prepares a list variables (and their associated tolerances) to be colocalized with eddies.\n",
    "    \"\"\"\n",
    "    Param = namedtuple('Param', ['table', 'variable', 'temporalTolerance', 'latTolerance', 'lonTolerance', 'depthTolerance'])\n",
    "    params = []\n",
    "\n",
    "    ######## satellite\n",
    "    params.append(Param('tblSST_AVHRR_OI_NRT', 'sst', 0, 0.5, 0.5, 5))\n",
    "#     params.append(Param('tblSSS_NRT', 'sss', 0, 0.5, 0.5, 5))\n",
    "    params.append(Param('tblCHL_REP', 'chl', 4, 0.5, 0.5, 5))\n",
    "#     params.append(Param('tblModis_AOD_REP', 'AOD', 15, 1, 1, 5))\n",
    "    params.append(Param('tblAltimetry_REP', 'sla', 0, 0.5, 0.5, 5))\n",
    "\n",
    "    ######## model\n",
    "    params.append(Param('tblPisces_NRT', 'NO3', 4, 0.5, 0.5, 5))\n",
    "#     params.append(Param('tblPisces_NRT', 'Fe', 4, 0.5, 0.5, 5))\n",
    "#     params.append(Param('tblPisces_NRT', 'O2', 4, 0.5, 0.5, 5))\n",
    "#     params.append(Param('tblPisces_NRT', 'PO4', 4, 0.5, 0.5, 5))\n",
    "#     params.append(Param('tblPisces_NRT', 'Si', 4, 0.5, 0.5, 5))\n",
    "#     params.append(Param('tblPisces_NRT', 'PP', 4, 0.5, 0.5, 5))\n",
    "#     params.append(Param('tblPisces_NRT', 'CHL', 4, 0.5, 0.5, 5))\n",
    "#     params.append(Param('tblDarwin_Nutrient', 'PO4', 2, 0.5, 0.5, 5))\n",
    "#     params.append(Param('tblDarwin_Nutrient', 'SiO2', 2, 0.5, 0.5, 5))\n",
    "#     params.append(Param('tblDarwin_Nutrient', 'O2', 2, 0.5, 0.5, 5))\n",
    "#     params.append(Param('tblDarwin_Ecosystem', 'phytoplankton', 2, 0.5, 0.5, 5))\n",
    "#     params.append(Param('tblDarwin_Ecosystem', 'zooplankton', 2, 0.5, 0.5, 5))\n",
    "#     params.append(Param('tblDarwin_Ecosystem', 'CHL', 2, 0.5, 0.5, 5))\n",
    "#     params.append(Param('tblDarwin_Ecosystem', 'primary_production', 2, 0.5, 0.5, 5))\n",
    "#     params.append(Param('tblDarwin_Phytoplankton', 'diatom', 2, 0.5, 0.5, 5))\n",
    "#     params.append(Param('tblDarwin_Phytoplankton', 'coccolithophore', 2, 0.5, 0.5, 5))\n",
    "#     params.append(Param('tblDarwin_Phytoplankton', 'picoeukaryote', 2, 0.5, 0.5, 5))\n",
    "#     params.append(Param('tblDarwin_Phytoplankton', 'picoprokaryote', 2, 0.5, 0.5, 5))\n",
    "#     params.append(Param('tblDarwin_Phytoplankton', 'mixotrophic_dinoflagellate', 2, 0.5, 0.5, 5))\n",
    "\n",
    "\n",
    "    tables, variables, temporalTolerance, latTolerance, lonTolerance, depthTolerance = [], [], [], [], [], []\n",
    "    for i in range(len(params)):\n",
    "        tables.append(params[i].table)\n",
    "        variables.append(params[i].variable)\n",
    "        temporalTolerance.append(params[i].temporalTolerance)\n",
    "        latTolerance.append(params[i].latTolerance)\n",
    "        lonTolerance.append(params[i].lonTolerance)\n",
    "        depthTolerance.append(params[i].depthTolerance)\n",
    "    return tables, variables, temporalTolerance, latTolerance, lonTolerance, depthTolerance\n",
    "\n",
    "\n",
    "\n",
    "def main(y1, y2, m1, m2, d1, d2, edd_lat1, edd_lat2, edd_lon1, edd_lon2):\n",
    "    \"\"\"\n",
    "    Instantiates the API class and using the 'match_covariate()' function colocalizes the retrieved eddies \n",
    "    with the specified variables. \n",
    "    \"\"\"\n",
    "    api = pycmap.API()\n",
    "    daysDir = './export/eddy/days/'\n",
    "    if not os.path.exists(daysDir): os.makedirs(daysDir) \n",
    "\n",
    "    days = sparse_dates(y1, y2, m1, m2, d1, d2)\n",
    "    tables, variables, temporalTolerance, latTolerance, lonTolerance, depthTolerance = match_params()\n",
    "\n",
    "    for day_ind, day in enumerate(days):\n",
    "        eddies = daily_eddies(api, str(day), edd_lat1, edd_lat2, edd_lon1, edd_lon2)\n",
    "        eddies['time'] = pd.to_datetime(eddies['time'])\n",
    "        for variable in variables:\n",
    "            eddies[variable] = None\n",
    "            eddies[variable+'_std'] = None\n",
    "            eddies[variable+'_bkg'] = None\n",
    "            eddies[variable+'_bkg_std'] = None\n",
    "        print('Day %s:  %d / %d' % (str(day), day_ind+1, len(days)))\n",
    "        for e in range(len(eddies)):\n",
    "            print('\\tEddy %d / %d' % (e+1, len(eddies)))\n",
    "            for i in range(len(variables)):\n",
    "                # print('\\t\\t%d. Matching %s' % (i+1, variables[i]))\n",
    "                dt1 = str(eddies.loc[e, 'time'] + timedelta(days=-temporalTolerance[i]))\n",
    "                dt2 = str(eddies.loc[e, 'time'] + timedelta(days=temporalTolerance[i]))\n",
    "                lat, del_lat = eddies.loc[e, 'lat'], latTolerance[i]\n",
    "                lon, del_lon = eddies.loc[e, 'lon'], lonTolerance[i]\n",
    "                depth, del_depth = 0, depthTolerance[i]\n",
    "                v, v_std, bkg, bkg_std = match_covariate(api, tables[i], variables[i], dt1, dt2, lat, del_lat, lon, del_lon, depth, del_depth)\n",
    "                eddies.loc[e, variables[i]] = v\n",
    "                eddies.loc[e, variables[i]+'_std'] = v_std\n",
    "                eddies.loc[e, variables[i]+'_bkg'] = bkg \n",
    "                eddies.loc[e, variables[i]+'_bkg_std'] = bkg_std\n",
    "        eddies.to_csv(daysDir+str(day.date())+'.csv', index=False)\n",
    "    return eddies\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "##############################\n",
    "#                            #\n",
    "#           main             #\n",
    "#                            #\n",
    "##############################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ### time window\n",
    "    y1, y2 = 2014, 2014\n",
    "    m1, m2 = 1, 1\n",
    "    d1, d2 = 1, 1\n",
    "    ### spatial range\n",
    "    edd_lat1, edd_lat2 = 20, 30\n",
    "    edd_lon1, edd_lon2 = -160, -150\n",
    "    eddies = main(y1, y2, m1, m2, d1, d2, edd_lat1, edd_lat2, edd_lon1, edd_lon2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"studyCase3\"></a>\n",
    "<a href=\"#toc\" style=\"float: right;\">Table of Contents</a>\n",
    "## Study Case 3: Colocalize Eddies with Seaflow (slides &rarr;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Mohammad Dehghani Ashkezari <mdehghan@uw.edu>\n",
    "\n",
    "Date: 2019-10-22\n",
    "\n",
    "Function: Colocalize (match) eddy data set with seaflow variables.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pycmap\n",
    "from collections import namedtuple\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "def match_params():\n",
    "    \"\"\"Creates a collection of variables (and their tolerances) to be colocalized with the seaflow data set.\"\"\"\n",
    "    Param = namedtuple('Param', ['table', 'variable', 'temporalTolerance', 'latTolerance', 'lonTolerance', 'depthTolerance'])\n",
    "    params = []\n",
    "    ######## other seaflow\n",
    "    params.append(Param('tblSeaFlow', 'prochloro_abundance', 1, 0.5, 0.5, 0))\n",
    "#     params.append(Param('tblSeaFlow', 'prochloro_diameter', 1, 0.5, 0.5, 0))\n",
    "#     params.append(Param('tblSeaFlow', 'prochloro_carbon_content', 1, 0.5, 0.5, 0))\n",
    "#     params.append(Param('tblSeaFlow', 'prochloro_biomass', 1, 0.5, 0.5, 0))\n",
    "#     params.append(Param('tblSeaFlow', 'synecho_abundance', 1, 0.5, 0.5, 0))\n",
    "#     params.append(Param('tblSeaFlow', 'synecho_diameter', 1, 0.5, 0.5, 0))\n",
    "#     params.append(Param('tblSeaFlow', 'synecho_carbon_content', 1, 0.5, 0.5, 0))\n",
    "#     params.append(Param('tblSeaFlow', 'synecho_biomass', 1, 0.5, 0.5, 0))\n",
    "#     params.append(Param('tblSeaFlow', 'picoeuk_abundance', 1, 0.5, 0.5, 0))\n",
    "#     params.append(Param('tblSeaFlow', 'picoeuk_diameter', 1, 0.5, 0.5, 0))\n",
    "#     params.append(Param('tblSeaFlow', 'picoeuk_carbon_content', 1, 0.5, 0.5, 0))\n",
    "#     params.append(Param('tblSeaFlow', 'picoeuk_biomass', 1, 0.5, 0.5, 0))\n",
    "#     params.append(Param('tblSeaFlow', 'total_biomass', 1, 0.5, 0.5, 0))\n",
    "\n",
    "    ######## eddy vars\n",
    "    params.append(Param('tblMesoscale_Eddy', 'eddy_polarity', 1, 0.5, 0.5, 0))\n",
    "    params.append(Param('tblMesoscale_Eddy', 'eddy_age', 1, 0.5, 0.5, 0))\n",
    "#     params.append(Param('tblMesoscale_Eddy', 'eddy_radius', 1, 0.5, 0.5, 0))\n",
    "#     params.append(Param('tblMesoscale_Eddy', 'eddy_A', 1, 0.5, 0.5, 0))\n",
    "#     params.append(Param('tblMesoscale_Eddy', 'eddy_U', 1, 0.5, 0.5, 0))\n",
    "#     params.append(Param('tblMesoscale_Eddy', 'track', 1, 0.5, 0.5, 0))\n",
    "\n",
    "    tables, variables, temporalTolerance, latTolerance, lonTolerance, depthTolerance = [], [], [], [], [], []\n",
    "    for i in range(len(params)):\n",
    "        tables.append(params[i].table)\n",
    "        variables.append(params[i].variable)\n",
    "        temporalTolerance.append(params[i].temporalTolerance)\n",
    "        latTolerance.append(params[i].latTolerance)\n",
    "        lonTolerance.append(params[i].lonTolerance)\n",
    "        depthTolerance.append(params[i].depthTolerance)\n",
    "    return tables, variables, temporalTolerance, latTolerance, lonTolerance, depthTolerance\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    api = pycmap.API()\n",
    "    days = api.query(\"SELECT DISTINCT CONVERT(DATE, [time]) [time] FROM tblSeaFlow where [time]<='2018-01-17' ORDER BY [time] DESC\")['time']\n",
    "    tables, variables, temporalTolerance, latTolerance, lonTolerance, depthTolerance = match_params()\n",
    "    df = pd.DataFrame({})\n",
    "    exportDir = './export/eddy/'\n",
    "    if not os.path.exists(exportDir): os.makedirs(exportDir) \n",
    "    for ind, day in enumerate(days):\n",
    "        day = day.split('T')[0]\n",
    "        print('\\n********************************')\n",
    "        print('Preparing %s (%d / %d) ...' % (day, ind, len(days)))\n",
    "        print('********************************\\n')\n",
    "        data = api.match(\n",
    "                         sourceTable='tblSeaFlow',\n",
    "                         sourceVar='',   \n",
    "                         targetTables=tables,\n",
    "                         targetVars=variables,\n",
    "                         dt1=day,\n",
    "                         dt2=day,\n",
    "                         lat1=-90,\n",
    "                         lat2=90,\n",
    "                         lon1=-180,\n",
    "                         lon2=180,\n",
    "                         depth1=0,\n",
    "                         depth2=5,\n",
    "                         temporalTolerance=temporalTolerance, \n",
    "                         latTolerance=latTolerance, \n",
    "                         lonTolerance=lonTolerance, \n",
    "                         depthTolerance=depthTolerance\n",
    "                         )\n",
    "        if len(df) < 1:\n",
    "            df = data\n",
    "        else:\n",
    "            df = pd.concat([df, data], ignore_index=True)    \n",
    "        data.to_csv('%s%s.csv' % (exportDir, day), index=False)\n",
    "    df.to_csv('%sedMatch.csv' % exportDir, index=False)    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "##############################\n",
    "#                            #\n",
    "#           main             #\n",
    "#                            #\n",
    "##############################\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
